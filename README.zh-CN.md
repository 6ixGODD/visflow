<div align="center">
<h1>VisFlow</h1>

[![PyPI version](https://badge.fury.io/py/visflow.svg)](https://badge.fury.io/py/visflow)
[![Python Version](https://img.shields.io/pypi/pyversions/visflow)](https://pypi.org/project/visflow/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

*A comprehensive computer vision framework for training, evaluation, and visualization*

[English](README.md) | ä¸­æ–‡

</div>

### ğŸš€ ç‰¹æ€§

- **ğŸ¯ ç®€æ˜“è®­ç»ƒ**: é€šè¿‡ç®€å•çš„ YAML é…ç½®è¿›è¡Œæ¨¡å‹è®­ç»ƒ
- **ğŸ”¥ GradCAM å¯è§†åŒ–**: å†…ç½®æ¨¡å‹å¯è§£é‡Šæ€§æ”¯æŒ
- **ğŸ—ï¸ å¤šç§æ¶æ„**: æ”¯æŒ torchvision ä¸­çš„ 50+ é¢„è®­ç»ƒæ¨¡å‹
- **ğŸ¨ å¯æ‰©å±•**: é€šè¿‡æ³¨å†Œç³»ç»Ÿè½»æ¾æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹
- **âš¡ CLI å’Œç¼–ç¨‹æ¥å£**: æ”¯æŒå‘½ä»¤è¡Œå’Œ Python API ä¸¤ç§ä½¿ç”¨æ–¹å¼
- **ğŸ“Š ä¸°å¯Œçš„æ—¥å¿—**: ç¾è§‚çš„ç»ˆç«¯è¾“å‡ºå’Œè¿›åº¦è·Ÿè¸ª

### ğŸ“¦ å®‰è£…

```bash
pip install visflow
```

### ğŸ¯ å¿«é€Ÿå¼€å§‹

#### è®­ç»ƒæ¨¡å‹

1. **åˆ›å»ºé…ç½®æ–‡ä»¶** (`config.yml`):

```yaml
model:
  architecture: resnet18 # æ¨¡å‹æ¶æ„
  pretrained: true       # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
  num_classes: 2         # åˆ†ç±»æ•°é‡

training:
  device: cuda         # è®¾å¤‡é€‰æ‹©
  batch_size: 32       # æ‰¹æ¬¡å¤§å°
  epochs: 10           # è®­ç»ƒè½®æ•°
  learning_rate: 0.001 # å­¦ä¹ ç‡
  optimizer: adam      # ä¼˜åŒ–å™¨

data:
  train_dir: ./data/train # è®­ç»ƒæ•°æ®ç›®å½•
  val_dir: ./data/val     # éªŒè¯æ•°æ®ç›®å½•
  test_dir: ./data/test   # æµ‹è¯•æ•°æ®ç›®å½•

output:
  output_dir: ./output           # è¾“å‡ºç›®å½•
  experiment_name: my-experiment # å®éªŒåç§°
```

2. **é€šè¿‡ CLI è®­ç»ƒ**:
```bash
visflow train --config config.yml
```

3. **æˆ–é€šè¿‡ Python API è®­ç»ƒ**:
```python
from visflow.resources.configs import TrainConfig
from visflow.pipelines.train import TrainPipeline

pipeline = TrainPipeline(TrainConfig.from_yaml('config.yml'))
pipeline()
```

#### GradCAM å¯è§†åŒ–

```bash
visflow gradcam \
    --ckpt-path model.pth \
    --image-path image.jpg \
    --output-dir ./output \
    --target-layer layer4 \
    --colormap jet
```

### ğŸ—ï¸ æ”¯æŒçš„æ¶æ„

Visflow æ”¯æŒ torchvision ä¸­çš„ 50+ æ¶æ„ï¼š

- **ResNet ç³»åˆ—**: resnet18, resnet34, resnet50, resnet101, resnet152, resnext50_32x4d ç­‰
- **EfficientNet ç³»åˆ—**: efficientnet_b0 åˆ° efficientnet_b7, efficientnet_v2_s/m/l
- **Vision Transformers**: vit_b_16, vit_b_32, vit_l_16, swin_t, swin_s, swin_b
- **MobileNet ç³»åˆ—**: mobilenet_v2, mobilenet_v3_small, mobilenet_v3_large
- **DenseNet ç³»åˆ—**: densenet121, densenet169, densenet201, densenet161
- **è¿˜æœ‰æ›´å¤š**: VGG, ConvNeXt, RegNet, MaxViT ç­‰

### ğŸ¨ è‡ªå®šä¹‰æ¨¡å‹

è½»æ¾æ·»åŠ æ‚¨è‡ªå·±çš„æ¨¡å‹ï¼š

```python
from visflow.resources.models import BaseClassifier, register_model

@register_model('my_custom_model')
class MyCustomModel(BaseClassifier):
    def __init__(self, num_classes: int):
        super().__init__(num_classes=num_classes)
        # æ‚¨çš„æ¨¡å‹å®ç°
        
    def forward(self, x):
        # å‰å‘ä¼ æ’­å®ç°
        pass
        
    def gradcam_layer(self):
        # è¿”å›æœ€åä¸€ä¸ªå·ç§¯å±‚ç”¨äº GradCAM
        return self.conv_layer
```

### ğŸ“– CLI å‚è€ƒ

#### è®­ç»ƒå‘½ä»¤
```bash
visflow train [OPTIONS]

é€‰é¡¹:
  -c, --config PATH     è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„ [å¿…éœ€]
  -v, --verbose         å¯ç”¨è¯¦ç»†æ—¥å¿—
  --help                æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º
```

#### GradCAM å‘½ä»¤
```bash
visflow gradcam [OPTIONS]

é€‰é¡¹:
  -k, --ckpt-path PATH      æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ [å¿…éœ€]
  -i, --image-path PATH     è¾“å…¥å›¾åƒè·¯å¾„ [å¿…éœ€]
  -o, --output-dir PATH     è¾“å‡ºç›®å½• [é»˜è®¤: ./output]
  -l, --target-layer TEXT   ç›®æ ‡å±‚åç§°
  -t, --target-class TEXT   ç›®æ ‡ç±»åˆ«ï¼ˆç´¢å¼•æˆ–åç§°ï¼‰
  -c, --colormap TEXT       é¢œè‰²æ˜ å°„ [é»˜è®¤: jet]
  --heatmap-only            ä»…ä¿å­˜çƒ­åŠ›å›¾
  --eigen-smooth            åº”ç”¨ç‰¹å¾å€¼å¹³æ»‘
  --aug-smooth              åº”ç”¨å¢å¼ºå¹³æ»‘
  -d, --device TEXT         è®¾å¤‡ (cpu/cuda)
  -v, --verbose             å¯ç”¨è¯¦ç»†æ—¥å¿—
```

### ğŸ“‹ é…ç½®é€‰é¡¹

<details>
<summary>ç¤ºä¾‹é…ç½®</summary>

```yaml
logging:
  backend: native  # Options: native, loguru
  loglevel: info   # Options: debug, info, warning, error, critical

seed: 42

model:
  architecture: resnet18
  pretrained: true
  num_classes: 2
  weights_path: ~  # Optional custom weights

training:
  device: cuda
  shuffle: true
  batch_size: 32
  weighted_sampling: false
  drop_last: false
  epochs: 10
  learning_rate: 0.001
  momentum: 0.9
  weight_decay: 0.0001
  optimizer: adam  # Options: sgd, adam, adamw
  lr_scheduler: ~  # Options: step, cosine, plateau
  early_stopping: true
  early_stopping_patience: 5
  label_smoothing: 0.0

testing:
  batch_size: 32

data:
  train_dir: ./data/train
  val_dir: ./data/val
  test_dir: ./data/test
  num_workers: 4
  pin_memory: false

resize:
  size: 224
  interpolation: bicubic
  antialias: true

normalization:
  enabled: true
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

augmentation:
  horizontal_flip:
    enabled: true
    p: 0.5
  rotation:
    enabled: false
    degrees: 30
  color_jitter:
    enabled: false
    brightness: 0.2
    contrast: 0.2
    saturation: 0.2
    hue: 0.1
  # ... more augmentation options

output:
  output_dir: ./output
  experiment_name: vision-research
  checkpoint_frequency: 10
```

</details>

è¯¦è§[ç¤ºä¾‹é…ç½®æ–‡ä»¶](.config.example.yml)ã€‚

### ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦æƒ…è¯·è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚
